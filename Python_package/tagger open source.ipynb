{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagger open source\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Copyright (C) 2011 by Alessandro Presta\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE\n",
    "\n",
    "\n",
    "'''\n",
    "======\n",
    "tagger\n",
    "======\n",
    "\n",
    "Module for extracting tags from text documents.\n",
    "                   \n",
    "Copyright (C) 2011 by Alessandro Presta\n",
    "\n",
    "Configuration\n",
    "=============\n",
    "\n",
    "Dependencies:\n",
    "python2.7, stemming, nltk (optional), lxml (optional), tkinter (optional)\n",
    "\n",
    "You can install the stemming package with::\n",
    "\n",
    "    $ easy_install stemming\n",
    "\n",
    "Usage\n",
    "=====\n",
    "\n",
    "Tagging a text document from Python::\n",
    "\n",
    "    import tagger\n",
    "    weights = pickle.load(open('data/dict.pkl', 'rb')) # or your own dictionary\n",
    "    myreader = tagger.Reader() # or your own reader class\n",
    "    mystemmer = tagger.Stemmer() # or your own stemmer class\n",
    "    myrater = tagger.Rater(weights) # or your own... (you got the idea)\n",
    "    mytagger = Tagger(myreader, mystemmer, myrater)\n",
    "    best_3_tags = mytagger(text_string, 3)\n",
    "\n",
    "Running the module as a script::\n",
    "\n",
    "    $ ./tagger.py <text document(s) to tag>\n",
    "\n",
    "Example::\n",
    "\n",
    "    $ ./tagger.py tests/*\n",
    "    Loading dictionary... \n",
    "    Tags for  tests/bbc1.txt :\n",
    "    ['bin laden', 'obama', 'pakistan', 'killed', 'raid']\n",
    "    Tags for  tests/bbc2.txt :\n",
    "    ['jo yeates', 'bristol', 'vincent tabak', 'murder', 'strangled']\n",
    "    Tags for  tests/bbc3.txt :\n",
    "    ['snp', 'party', 'election', 'scottish', 'labour']\n",
    "    Tags for  tests/guardian1.txt :\n",
    "    ['bin laden', 'al-qaida', 'killed', 'pakistan', 'al-fawwaz']\n",
    "    Tags for  tests/guardian2.txt :\n",
    "    ['clegg', 'tory', 'lib dem', 'party', 'coalition']\n",
    "    Tags for  tests/post1.txt :\n",
    "    ['sony', 'stolen', 'playstation network', 'hacker attack', 'lawsuit']\n",
    "    Tags for  tests/wikipedia1.txt :\n",
    "    ['universe', 'anthropic principle', 'observed', 'cosmological', 'theory']\n",
    "    Tags for  tests/wikipedia2.txt :\n",
    "    ['beetroot', 'beet', 'betaine', 'blood pressure', 'dietary nitrate']\n",
    "    Tags for  tests/wikipedia3.txt :\n",
    "    ['the lounge lizards', 'jazz', 'john lurie', 'musical', 'albums']\n",
    "'''\n",
    "\n",
    "import collections\n",
    "import re\n",
    "\n",
    "\n",
    "class Tag:\n",
    "    '''\n",
    "    General class for tags (small units of text)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, string, stem=None, rating=1.0, proper=False,\n",
    "                 terminal=False):\n",
    "        '''\n",
    "        @param string:   the actual representation of the tag\n",
    "        @param stem:     the internal (usually stemmed) representation;\n",
    "                         tags with the same stem are regarded as equal\n",
    "        @param rating:   a measure of the tag's relevance in the interval [0,1]\n",
    "        @param proper:   whether the tag is a proper noun\n",
    "        @param terminal: set to True if the tag is at the end of a phrase\n",
    "                         (or anyway it cannot be logically merged to the\n",
    "                         following one)\n",
    "\n",
    "        @returns: a new L{Tag} object\n",
    "        '''\n",
    "            \n",
    "        self.string  = string\n",
    "        self.stem = stem or string\n",
    "        self.rating = rating\n",
    "        self.proper = proper\n",
    "        self.terminal = terminal\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return self.stem == other.stem\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.string)\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.rating > other.rating\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.stem)\n",
    "\n",
    "\n",
    "class MultiTag(Tag):\n",
    "    '''\n",
    "    Class for aggregates of tags (usually next to each other in the document)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tail, head=None):\n",
    "        '''\n",
    "        @param tail: the L{Tag} object to add to the first part (head)\n",
    "        @param head: the (eventually absent) L{MultiTag} to be extended\n",
    "\n",
    "        @returns: a new L{MultiTag} object\n",
    "        '''\n",
    "        \n",
    "        if not head:\n",
    "            Tag.__init__(self, tail.string, tail.stem, tail.rating,\n",
    "                         tail.proper, tail.terminal)\n",
    "            self.size = 1\n",
    "            self.subratings = [self.rating]\n",
    "        else:\n",
    "            self.string = ' '.join([head.string, tail.string])\n",
    "            self.stem = ' '.join([head.stem, tail.stem])\n",
    "            self.size = head.size + 1\n",
    "\n",
    "            self.proper = (head.proper and tail.proper)\n",
    "            self.terminal = tail.terminal\n",
    "\n",
    "            self.subratings = head.subratings + [tail.rating]\n",
    "            self.rating = self.combined_rating()\n",
    "                                           \n",
    "    def combined_rating(self):\n",
    "        '''\n",
    "        Method that computes the multitag's rating from the ratings of unit\n",
    "        subtags\n",
    "\n",
    "        (the default implementation uses the geometric mean - with a special\n",
    "        treatment for proper nouns - but this method can be overridden)\n",
    "        \n",
    "        @returns: the rating of the multitag\n",
    "        '''\n",
    "        \n",
    "        # by default, the rating of a multitag is the geometric mean of its\n",
    "        # unit subtags' ratings\n",
    "        product = reduce(lambda x, y: x * y, self.subratings, 1.0)\n",
    "        root = self.size\n",
    "        \n",
    "        # but proper nouns shouldn't be penalized by stopwords\n",
    "        if product == 0.0 and self.proper:\n",
    "            nonzero = [r for r in self.subratings if r > 0.0]\n",
    "            if len(nonzero) == 0:\n",
    "                return 0.0\n",
    "            product = reduce(lambda x, y: x * y, nonzero, 1.0)\n",
    "            root = len(nonzero)\n",
    "            \n",
    "        return product ** (1.0 / root)\n",
    "\n",
    "    \n",
    "class Reader:\n",
    "    '''\n",
    "    Class for parsing a string of text to obtain tags\n",
    "\n",
    "    (it just turns the string to lowercase and splits it according to\n",
    "    whitespaces and punctuation, identifying proper nouns and terminal words;\n",
    "    different rules and formats other than plain text could be used)\n",
    "    '''\n",
    "\n",
    "    match_apostrophes = re.compile('`|â€™')\n",
    "    match_paragraphs = re.compile('[\\.\\?!\\t\\n\\r\\f\\v]+')\n",
    "    match_phrases = re.compile('[,;:\\(\\)\\[\\]\\{\\}<>]+')\n",
    "    match_words = re.compile('[\\w\\-\\'_/&]+')\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        '''\n",
    "        @param text: the string of text to be tagged\n",
    "\n",
    "        @returns: a list of tags respecting the order in the text\n",
    "        '''\n",
    "\n",
    "        text = self.preprocess(text)\n",
    "\n",
    "        # split by full stops, newlines, question marks...\n",
    "        paragraphs = self.match_paragraphs.split(text)\n",
    "\n",
    "        tags = []\n",
    "\n",
    "        for par in paragraphs:\n",
    "            # split by commas, colons, parentheses...\n",
    "            phrases = self.match_phrases.split(par)\n",
    "\n",
    "            if len(phrases) > 0:\n",
    "                # first phrase of a paragraph\n",
    "                words = self.match_words.findall(phrases[0])\n",
    "                if len(words) > 1:\n",
    "                    tags.append(Tag(words[0].lower()))\n",
    "                    for w in words[1:-1]:\n",
    "                        tags.append(Tag(w.lower(), proper=w[0].isupper()))\n",
    "                    tags.append(Tag(words[-1].lower(),\n",
    "                                    proper=words[-1][0].isupper(),\n",
    "                                    terminal=True))\n",
    "                elif len(words) == 1:\n",
    "                    tags.append(Tag(words[0].lower(), terminal=True))\n",
    "\n",
    "            # following phrases\n",
    "            for phr in phrases[1:]:\n",
    "                words = self.match_words.findall(phr)\n",
    "                if len(words) > 1:\n",
    "                    for w in words[:-1]:\n",
    "                        tags.append(Tag(w.lower(), proper=w[0].isupper()))\n",
    "                if len(words) > 0:\n",
    "                    tags.append(Tag(words[-1].lower(),\n",
    "                                    proper=words[-1][0].isupper(),\n",
    "                                    terminal=True))\n",
    "\n",
    "        return tags\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        '''\n",
    "        @param text: a string containing the text document to perform any\n",
    "                     required transformation before splitting\n",
    "\n",
    "        @returns:    the processed text\n",
    "        '''\n",
    "        \n",
    "        text = self.match_apostrophes.sub('\\'', text)\n",
    "        return text\n",
    "\n",
    "    \n",
    "class Stemmer:\n",
    "    '''\n",
    "    Class for extracting the stem of a word\n",
    "    \n",
    "    (by default it uses a simple open-source implementation of Porter's\n",
    "    algorithm; this can be improved a lot, so experimenting with different ones\n",
    "    is advisable; nltk.stem provides different algorithms for many languages)\n",
    "    '''\n",
    "\n",
    "    match_contractions = re.compile('(\\w+)\\'(m|re|d|ve|s|ll|t)?')\n",
    "\n",
    "    def __init__(self, stemmer=None):\n",
    "        '''\n",
    "        @param stemmer: an object or module with a 'stem' method (defaults to\n",
    "                        stemming.porter2)\n",
    "\n",
    "        @returns: a new L{Stemmer} object\n",
    "        '''\n",
    "        \n",
    "        if not stemmer:\n",
    "            from stemming import porter2\n",
    "            stemmer = porter2\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def __call__(self, tag):\n",
    "        '''\n",
    "        @param tag: the tag to be stemmed\n",
    "\n",
    "        @returns: the stemmed tag\n",
    "        '''\n",
    "\n",
    "        string = self.preprocess(tag.string)\n",
    "        tag.stem = self.stemmer.stem(string)\n",
    "        return tag    \n",
    "        \n",
    "    def preprocess(self, string):\n",
    "        '''\n",
    "        @param string: a string to be treated before passing it to the stemmer\n",
    "\n",
    "        @returns: the processed string\n",
    "        '''\n",
    "\n",
    "        # get rid of contractions and possessive forms\n",
    "        match = self.match_contractions.match(string)\n",
    "        if match: return match.group(1)\n",
    "        else: return string\n",
    "    \n",
    "\n",
    "class Rater:\n",
    "    '''\n",
    "    Class for estimating the relevance of tags\n",
    "\n",
    "    (the default implementation uses TF (term frequency) multiplied by weight,\n",
    "    but any other reasonable measure is fine; a quite rudimental heuristic\n",
    "    tries to discard redundant tags)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, weights, multitag_size=3):\n",
    "        '''\n",
    "        @param weights:       a dictionary of weights normalized in the\n",
    "                              interval [0,1]\n",
    "        @param multitag_size: maximum size of tags formed by multiple unit\n",
    "                              tags\n",
    "\n",
    "        @returns: a new L{Rater} object\n",
    "        '''\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.multitag_size = multitag_size\n",
    "        \n",
    "    def __call__(self, tags):\n",
    "        '''\n",
    "        @param tags: a list of (preferably stemmed) tags\n",
    "\n",
    "        @returns: a list of unique (multi)tags sorted by relevance\n",
    "        '''\n",
    "\n",
    "        self.rate_tags(tags)\n",
    "        multitags = self.create_multitags(tags)\n",
    "\n",
    "        # keep most frequent version of each tag\n",
    "        clusters = collections.defaultdict(collections.Counter)\n",
    "        proper = collections.defaultdict(int)\n",
    "        ratings = collections.defaultdict(float)\n",
    "        \n",
    "        for t in multitags:\n",
    "            clusters[t][t.string] += 1\n",
    "            if t.proper:\n",
    "                proper[t] += 1\n",
    "                ratings[t] = max(ratings[t], t.rating)\n",
    "\n",
    "        term_count = collections.Counter(multitags)\n",
    "                \n",
    "        for t, cnt in term_count.iteritems():\n",
    "            t.string = clusters[t].most_common(1)[0][0]\n",
    "            proper_freq = proper[t] / float(cnt)\n",
    "            if proper_freq >= 0.5:\n",
    "                t.proper = True\n",
    "                t.rating = ratings[t]\n",
    "        \n",
    "        # purge duplicates and one-character tags\n",
    "        unique_tags = set(t for t in term_count if len(t.string) > 1)\n",
    "        # remove redundant tags\n",
    "        for t, cnt in term_count.iteritems():\n",
    "            words = t.stem.split()\n",
    "            for l in xrange(1, len(words)):\n",
    "                for i in xrange(len(words) - l + 1):\n",
    "                    s = Tag(' '.join(words[i:i + l]))\n",
    "                    relative_freq = float(cnt) / term_count[s]\n",
    "                    if ((relative_freq == 1.0 and t.proper) or\n",
    "                        (relative_freq >= 0.5 and t.rating > 0.0)):\n",
    "                        unique_tags.discard(s)\n",
    "                    else:\n",
    "                        unique_tags.discard(t)\n",
    "        \n",
    "        return sorted(unique_tags)\n",
    "\n",
    "    def rate_tags(self, tags):\n",
    "        '''\n",
    "        @param tags: a list of tags to be assigned a rating\n",
    "        '''\n",
    "        \n",
    "        term_count = collections.Counter(tags)\n",
    "        \n",
    "        for t in tags:\n",
    "            # rating of a single tag is term frequency * weight\n",
    "            t.rating = float(term_count[t]) / len(tags) * \\\n",
    "                self.weights.get(t.stem, 1.0)\n",
    "    \n",
    "    def create_multitags(self, tags):\n",
    "        '''\n",
    "        @param tags: a list of tags (respecting the order in the text)\n",
    "\n",
    "        @returns: a list of multitags\n",
    "        '''\n",
    "        \n",
    "        multitags = []\n",
    "        \n",
    "        for i in xrange(len(tags)):\n",
    "            t = MultiTag(tags[i])\n",
    "            multitags.append(t)\n",
    "            for j in xrange(1, self.multitag_size):\n",
    "                if t.terminal or i + j >= len(tags):\n",
    "                    break\n",
    "                else:\n",
    "                    t = MultiTag(tags[i + j], t)\n",
    "                    multitags.append(t)\n",
    "\n",
    "        return multitags\n",
    "    \n",
    "    \n",
    "class Tagger:\n",
    "    '''\n",
    "    Master class for tagging text documents\n",
    "\n",
    "    (this is a simple interface that should allow convenient experimentation\n",
    "    by using different classes as building blocks)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, reader, stemmer, rater):\n",
    "        '''\n",
    "        @param reader: a L{Reader} object\n",
    "        @param stemmer: a L{Stemmer} object\n",
    "        @param rater: a L{Rater} object\n",
    "\n",
    "        @returns: a new L{Tagger} object\n",
    "        '''\n",
    "        \n",
    "        self.reader = reader\n",
    "        self.stemmer = stemmer\n",
    "        self.rater = rater\n",
    "\n",
    "    def __call__(self, text, tags_number=5):\n",
    "        '''\n",
    "        @param text:        the string of text to be tagged\n",
    "        @param tags_number: number of best tags to be returned\n",
    "\n",
    "        Returns: a list of (hopefully) relevant tags\n",
    "        ''' \n",
    "\n",
    "        tags = self.reader(text)\n",
    "        tags = map(self.stemmer, tags)\n",
    "        tags = self.rater(tags)\n",
    "\n",
    "        return tags[:tags_number]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import glob\n",
    "    import pickle\n",
    "    import sys\n",
    "\n",
    "    if len(sys.argv) < 2:\n",
    "        print ('No arguments given, running tests: ')\n",
    "        documents = glob.glob('tests/*')\n",
    "    else:\n",
    "        documents = sys.argv[1:]\n",
    "    \n",
    "    print ('Loading dictionary... ')\n",
    "    weights = pickle.load(open('data/dict.pkl', 'rb'))\n",
    "\n",
    "    tagger = Tagger(Reader(), Stemmer(), Rater(weights))\n",
    "\n",
    "    for doc in documents:\n",
    "        with open(doc, 'r') as file:\n",
    "            print ('Tags for ', doc, ':')\n",
    "            print (tagger(file.read()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
