{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9436402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functools open source\n",
    "\n",
    "\"\"\"functools.py - Tools for working with functions and callable objects\"\"\"\n",
    "# Python module wrapper for _functools C module\n",
    "# to allow utilities written in Python to be added\n",
    "# to the functools module.\n",
    "# Written by Nick Coghlan <ncoghlan at gmail.com>,\n",
    "# Raymond Hettinger <python at rcn.com>,\n",
    "# and ≈Åukasz Langa <lukasz at langa.pl>.\n",
    "#   Copyright (C) 2006-2013 Python Software Foundation.\n",
    "# See C source code for _functools credits/copyright\n",
    "\n",
    "__all__ = ['update_wrapper', 'wraps', 'WRAPPER_ASSIGNMENTS', 'WRAPPER_UPDATES',\n",
    "           'total_ordering', 'cache', 'cmp_to_key', 'lru_cache', 'reduce',\n",
    "           'partial', 'partialmethod', 'singledispatch', 'singledispatchmethod',\n",
    "           'cached_property']\n",
    "\n",
    "from abc import get_cache_token\n",
    "from collections import namedtuple\n",
    "# import types, weakref  # Deferred to single_dispatch()\n",
    "from reprlib import recursive_repr\n",
    "from _thread import RLock\n",
    "from types import GenericAlias\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### update_wrapper() and wraps() decorator\n",
    "################################################################################\n",
    "\n",
    "# update_wrapper() and wraps() are tools to help write\n",
    "# wrapper functions that can handle naive introspection\n",
    "\n",
    "WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__',\n",
    "                       '__annotations__')\n",
    "WRAPPER_UPDATES = ('__dict__',)\n",
    "def update_wrapper(wrapper,\n",
    "                   wrapped,\n",
    "                   assigned = WRAPPER_ASSIGNMENTS,\n",
    "                   updated = WRAPPER_UPDATES):\n",
    "    \"\"\"Update a wrapper function to look like the wrapped function\n",
    "       wrapper is the function to be updated\n",
    "       wrapped is the original function\n",
    "       assigned is a tuple naming the attributes assigned directly\n",
    "       from the wrapped function to the wrapper function (defaults to\n",
    "       functools.WRAPPER_ASSIGNMENTS)\n",
    "       updated is a tuple naming the attributes of the wrapper that\n",
    "       are updated with the corresponding attribute from the wrapped\n",
    "       function (defaults to functools.WRAPPER_UPDATES)\n",
    "    \"\"\"\n",
    "    for attr in assigned:\n",
    "        try:\n",
    "            value = getattr(wrapped, attr)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        else:\n",
    "            setattr(wrapper, attr, value)\n",
    "    for attr in updated:\n",
    "        getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n",
    "    # Issue #17482: set __wrapped__ last so we don't inadvertently copy it\n",
    "    # from the wrapped function when updating __dict__\n",
    "    wrapper.__wrapped__ = wrapped\n",
    "    # Return the wrapper so this can be used as a decorator via partial()\n",
    "    return wrapper\n",
    "\n",
    "def wraps(wrapped,\n",
    "          assigned = WRAPPER_ASSIGNMENTS,\n",
    "          updated = WRAPPER_UPDATES):\n",
    "    \"\"\"Decorator factory to apply update_wrapper() to a wrapper function\n",
    "       Returns a decorator that invokes update_wrapper() with the decorated\n",
    "       function as the wrapper argument and the arguments to wraps() as the\n",
    "       remaining arguments. Default arguments are as for update_wrapper().\n",
    "       This is a convenience function to simplify applying partial() to\n",
    "       update_wrapper().\n",
    "    \"\"\"\n",
    "    return partial(update_wrapper, wrapped=wrapped,\n",
    "                   assigned=assigned, updated=updated)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### total_ordering class decorator\n",
    "################################################################################\n",
    "\n",
    "# The total ordering functions all invoke the root magic method directly\n",
    "# rather than using the corresponding operator.  This avoids possible\n",
    "# infinite recursion that could occur when the operator dispatch logic\n",
    "# detects a NotImplemented result and then calls a reflected method.\n",
    "\n",
    "def _gt_from_lt(self, other):\n",
    "    'Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).'\n",
    "    op_result = type(self).__lt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result and self != other\n",
    "\n",
    "def _le_from_lt(self, other):\n",
    "    'Return a <= b.  Computed by @total_ordering from (a < b) or (a == b).'\n",
    "    op_result = type(self).__lt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return op_result or self == other\n",
    "\n",
    "def _ge_from_lt(self, other):\n",
    "    'Return a >= b.  Computed by @total_ordering from (not a < b).'\n",
    "    op_result = type(self).__lt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result\n",
    "\n",
    "def _ge_from_le(self, other):\n",
    "    'Return a >= b.  Computed by @total_ordering from (not a <= b) or (a == b).'\n",
    "    op_result = type(self).__le__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result or self == other\n",
    "\n",
    "def _lt_from_le(self, other):\n",
    "    'Return a < b.  Computed by @total_ordering from (a <= b) and (a != b).'\n",
    "    op_result = type(self).__le__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return op_result and self != other\n",
    "\n",
    "def _gt_from_le(self, other):\n",
    "    'Return a > b.  Computed by @total_ordering from (not a <= b).'\n",
    "    op_result = type(self).__le__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result\n",
    "\n",
    "def _lt_from_gt(self, other):\n",
    "    'Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).'\n",
    "    op_result = type(self).__gt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result and self != other\n",
    "\n",
    "def _ge_from_gt(self, other):\n",
    "    'Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).'\n",
    "    op_result = type(self).__gt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return op_result or self == other\n",
    "\n",
    "def _le_from_gt(self, other):\n",
    "    'Return a <= b.  Computed by @total_ordering from (not a > b).'\n",
    "    op_result = type(self).__gt__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result\n",
    "\n",
    "def _le_from_ge(self, other):\n",
    "    'Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).'\n",
    "    op_result = type(self).__ge__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result or self == other\n",
    "\n",
    "def _gt_from_ge(self, other):\n",
    "    'Return a > b.  Computed by @total_ordering from (a >= b) and (a != b).'\n",
    "    op_result = type(self).__ge__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return op_result and self != other\n",
    "\n",
    "def _lt_from_ge(self, other):\n",
    "    'Return a < b.  Computed by @total_ordering from (not a >= b).'\n",
    "    op_result = type(self).__ge__(self, other)\n",
    "    if op_result is NotImplemented:\n",
    "        return op_result\n",
    "    return not op_result\n",
    "\n",
    "_convert = {\n",
    "    '__lt__': [('__gt__', _gt_from_lt),\n",
    "               ('__le__', _le_from_lt),\n",
    "               ('__ge__', _ge_from_lt)],\n",
    "    '__le__': [('__ge__', _ge_from_le),\n",
    "               ('__lt__', _lt_from_le),\n",
    "               ('__gt__', _gt_from_le)],\n",
    "    '__gt__': [('__lt__', _lt_from_gt),\n",
    "               ('__ge__', _ge_from_gt),\n",
    "               ('__le__', _le_from_gt)],\n",
    "    '__ge__': [('__le__', _le_from_ge),\n",
    "               ('__gt__', _gt_from_ge),\n",
    "               ('__lt__', _lt_from_ge)]\n",
    "}\n",
    "\n",
    "def total_ordering(cls):\n",
    "    \"\"\"Class decorator that fills in missing ordering methods\"\"\"\n",
    "    # Find user-defined comparisons (not those inherited from object).\n",
    "    roots = {op for op in _convert if getattr(cls, op, None) is not getattr(object, op, None)}\n",
    "    if not roots:\n",
    "        raise ValueError('must define at least one ordering operation: < > <= >=')\n",
    "    root = max(roots)       # prefer __lt__ to __le__ to __gt__ to __ge__\n",
    "    for opname, opfunc in _convert[root]:\n",
    "        if opname not in roots:\n",
    "            opfunc.__name__ = opname\n",
    "            setattr(cls, opname, opfunc)\n",
    "    return cls\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### cmp_to_key() function converter\n",
    "################################################################################\n",
    "\n",
    "def cmp_to_key(mycmp):\n",
    "    \"\"\"Convert a cmp= function into a key= function\"\"\"\n",
    "    class K(object):\n",
    "        __slots__ = ['obj']\n",
    "        def __init__(self, obj):\n",
    "            self.obj = obj\n",
    "        def __lt__(self, other):\n",
    "            return mycmp(self.obj, other.obj) < 0\n",
    "        def __gt__(self, other):\n",
    "            return mycmp(self.obj, other.obj) > 0\n",
    "        def __eq__(self, other):\n",
    "            return mycmp(self.obj, other.obj) == 0\n",
    "        def __le__(self, other):\n",
    "            return mycmp(self.obj, other.obj) <= 0\n",
    "        def __ge__(self, other):\n",
    "            return mycmp(self.obj, other.obj) >= 0\n",
    "        __hash__ = None\n",
    "    return K\n",
    "\n",
    "try:\n",
    "    from _functools import cmp_to_key\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### reduce() sequence to a single item\n",
    "################################################################################\n",
    "\n",
    "_initial_missing = object()\n",
    "\n",
    "def reduce(function, sequence, initial=_initial_missing):\n",
    "    \"\"\"\n",
    "    reduce(function, iterable[, initial]) -> value\n",
    "    Apply a function of two arguments cumulatively to the items of a sequence\n",
    "    or iterable, from left to right, so as to reduce the iterable to a single\n",
    "    value.  For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n",
    "    ((((1+2)+3)+4)+5).  If initial is present, it is placed before the items\n",
    "    of the iterable in the calculation, and serves as a default when the\n",
    "    iterable is empty.\n",
    "    \"\"\"\n",
    "\n",
    "    it = iter(sequence)\n",
    "\n",
    "    if initial is _initial_missing:\n",
    "        try:\n",
    "            value = next(it)\n",
    "        except StopIteration:\n",
    "            raise TypeError(\n",
    "                \"reduce() of empty iterable with no initial value\") from None\n",
    "    else:\n",
    "        value = initial\n",
    "\n",
    "    for element in it:\n",
    "        value = function(value, element)\n",
    "\n",
    "    return value\n",
    "\n",
    "try:\n",
    "    from _functools import reduce\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### partial() argument application\n",
    "################################################################################\n",
    "\n",
    "# Purely functional, no descriptor behaviour\n",
    "class partial:\n",
    "    \"\"\"New function with partial application of the given arguments\n",
    "    and keywords.\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = \"func\", \"args\", \"keywords\", \"__dict__\", \"__weakref__\"\n",
    "\n",
    "    def __new__(cls, func, /, *args, **keywords):\n",
    "        if not callable(func):\n",
    "            raise TypeError(\"the first argument must be callable\")\n",
    "\n",
    "        if hasattr(func, \"func\"):\n",
    "            args = func.args + args\n",
    "            keywords = {**func.keywords, **keywords}\n",
    "            func = func.func\n",
    "\n",
    "        self = super(partial, cls).__new__(cls)\n",
    "\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "        self.keywords = keywords\n",
    "        return self\n",
    "\n",
    "    def __call__(self, /, *args, **keywords):\n",
    "        keywords = {**self.keywords, **keywords}\n",
    "        return self.func(*self.args, *args, **keywords)\n",
    "\n",
    "    @recursive_repr()\n",
    "    def __repr__(self):\n",
    "        qualname = type(self).__qualname__\n",
    "        args = [repr(self.func)]\n",
    "        args.extend(repr(x) for x in self.args)\n",
    "        args.extend(f\"{k}={v!r}\" for (k, v) in self.keywords.items())\n",
    "        if type(self).__module__ == \"functools\":\n",
    "            return f\"functools.{qualname}({', '.join(args)})\"\n",
    "        return f\"{qualname}({', '.join(args)})\"\n",
    "\n",
    "    def __reduce__(self):\n",
    "        return type(self), (self.func,), (self.func, self.args,\n",
    "               self.keywords or None, self.__dict__ or None)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if not isinstance(state, tuple):\n",
    "            raise TypeError(\"argument to __setstate__ must be a tuple\")\n",
    "        if len(state) != 4:\n",
    "            raise TypeError(f\"expected 4 items in state, got {len(state)}\")\n",
    "        func, args, kwds, namespace = state\n",
    "        if (not callable(func) or not isinstance(args, tuple) or\n",
    "           (kwds is not None and not isinstance(kwds, dict)) or\n",
    "           (namespace is not None and not isinstance(namespace, dict))):\n",
    "            raise TypeError(\"invalid partial state\")\n",
    "\n",
    "        args = tuple(args) # just in case it's a subclass\n",
    "        if kwds is None:\n",
    "            kwds = {}\n",
    "        elif type(kwds) is not dict: # XXX does it need to be *exactly* dict?\n",
    "            kwds = dict(kwds)\n",
    "        if namespace is None:\n",
    "            namespace = {}\n",
    "\n",
    "        self.__dict__ = namespace\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "        self.keywords = kwds\n",
    "\n",
    "try:\n",
    "    from _functools import partial\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Descriptor version\n",
    "class partialmethod(object):\n",
    "    \"\"\"Method descriptor with partial application of the given arguments\n",
    "    and keywords.\n",
    "    Supports wrapping existing descriptors and handles non-descriptor\n",
    "    callables as instance methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, func, /, *args, **keywords):\n",
    "        if not callable(func) and not hasattr(func, \"__get__\"):\n",
    "            raise TypeError(\"{!r} is not callable or a descriptor\"\n",
    "                                 .format(func))\n",
    "\n",
    "        # func could be a descriptor like classmethod which isn't callable,\n",
    "        # so we can't inherit from partial (it verifies func is callable)\n",
    "        if isinstance(func, partialmethod):\n",
    "            # flattening is mandatory in order to place cls/self before all\n",
    "            # other arguments\n",
    "            # it's also more efficient since only one function will be called\n",
    "            self.func = func.func\n",
    "            self.args = func.args + args\n",
    "            self.keywords = {**func.keywords, **keywords}\n",
    "        else:\n",
    "            self.func = func\n",
    "            self.args = args\n",
    "            self.keywords = keywords\n",
    "\n",
    "    def __repr__(self):\n",
    "        args = \", \".join(map(repr, self.args))\n",
    "        keywords = \", \".join(\"{}={!r}\".format(k, v)\n",
    "                                 for k, v in self.keywords.items())\n",
    "        format_string = \"{module}.{cls}({func}, {args}, {keywords})\"\n",
    "        return format_string.format(module=self.__class__.__module__,\n",
    "                                    cls=self.__class__.__qualname__,\n",
    "                                    func=self.func,\n",
    "                                    args=args,\n",
    "                                    keywords=keywords)\n",
    "\n",
    "    def _make_unbound_method(self):\n",
    "        def _method(cls_or_self, /, *args, **keywords):\n",
    "            keywords = {**self.keywords, **keywords}\n",
    "            return self.func(cls_or_self, *self.args, *args, **keywords)\n",
    "        _method.__isabstractmethod__ = self.__isabstractmethod__\n",
    "        _method._partialmethod = self\n",
    "        return _method\n",
    "\n",
    "    def __get__(self, obj, cls=None):\n",
    "        get = getattr(self.func, \"__get__\", None)\n",
    "        result = None\n",
    "        if get is not None:\n",
    "            new_func = get(obj, cls)\n",
    "            if new_func is not self.func:\n",
    "                # Assume __get__ returning something new indicates the\n",
    "                # creation of an appropriate callable\n",
    "                result = partial(new_func, *self.args, **self.keywords)\n",
    "                try:\n",
    "                    result.__self__ = new_func.__self__\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        if result is None:\n",
    "            # If the underlying descriptor didn't do anything, treat this\n",
    "            # like an instance method\n",
    "            result = self._make_unbound_method().__get__(obj, cls)\n",
    "        return result\n",
    "\n",
    "    @property\n",
    "    def __isabstractmethod__(self):\n",
    "        return getattr(self.func, \"__isabstractmethod__\", False)\n",
    "\n",
    "    __class_getitem__ = classmethod(GenericAlias)\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "def _unwrap_partial(func):\n",
    "    while isinstance(func, partial):\n",
    "        func = func.func\n",
    "    return func\n",
    "\n",
    "################################################################################\n",
    "### LRU Cache function decorator\n",
    "################################################################################\n",
    "\n",
    "_CacheInfo = namedtuple(\"CacheInfo\", [\"hits\", \"misses\", \"maxsize\", \"currsize\"])\n",
    "\n",
    "class _HashedSeq(list):\n",
    "    \"\"\" This class guarantees that hash() will be called no more than once\n",
    "        per element.  This is important because the lru_cache() will hash\n",
    "        the key multiple times on a cache miss.\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = 'hashvalue'\n",
    "\n",
    "    def __init__(self, tup, hash=hash):\n",
    "        self[:] = tup\n",
    "        self.hashvalue = hash(tup)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.hashvalue\n",
    "\n",
    "def _make_key(args, kwds, typed,\n",
    "             kwd_mark = (object(),),\n",
    "             fasttypes = {int, str},\n",
    "             tuple=tuple, type=type, len=len):\n",
    "    \"\"\"Make a cache key from optionally typed positional and keyword arguments\n",
    "    The key is constructed in a way that is flat as possible rather than\n",
    "    as a nested structure that would take more memory.\n",
    "    If there is only a single argument and its data type is known to cache\n",
    "    its hash value, then that argument is returned without a wrapper.  This\n",
    "    saves space and improves lookup speed.\n",
    "    \"\"\"\n",
    "    # All of code below relies on kwds preserving the order input by the user.\n",
    "    # Formerly, we sorted() the kwds before looping.  The new way is *much*\n",
    "    # faster; however, it means that f(x=1, y=2) will now be treated as a\n",
    "    # distinct call from f(y=2, x=1) which will be cached separately.\n",
    "    key = args\n",
    "    if kwds:\n",
    "        key += kwd_mark\n",
    "        for item in kwds.items():\n",
    "            key += item\n",
    "    if typed:\n",
    "        key += tuple(type(v) for v in args)\n",
    "        if kwds:\n",
    "            key += tuple(type(v) for v in kwds.values())\n",
    "    elif len(key) == 1 and type(key[0]) in fasttypes:\n",
    "        return key[0]\n",
    "    return _HashedSeq(key)\n",
    "\n",
    "def lru_cache(maxsize=128, typed=False):\n",
    "    \"\"\"Least-recently-used cache decorator.\n",
    "    If *maxsize* is set to None, the LRU features are disabled and the cache\n",
    "    can grow without bound.\n",
    "    If *typed* is True, arguments of different types will be cached separately.\n",
    "    For example, f(3.0) and f(3) will be treated as distinct calls with\n",
    "    distinct results.\n",
    "    Arguments to the cached function must be hashable.\n",
    "    View the cache statistics named tuple (hits, misses, maxsize, currsize)\n",
    "    with f.cache_info().  Clear the cache and statistics with f.cache_clear().\n",
    "    Access the underlying function with f.__wrapped__.\n",
    "    See:  https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)\n",
    "    \"\"\"\n",
    "\n",
    "    # Users should only access the lru_cache through its public API:\n",
    "    #       cache_info, cache_clear, and f.__wrapped__\n",
    "    # The internals of the lru_cache are encapsulated for thread safety and\n",
    "    # to allow the implementation to change (including a possible C version).\n",
    "\n",
    "    if isinstance(maxsize, int):\n",
    "        # Negative maxsize is treated as 0\n",
    "        if maxsize < 0:\n",
    "            maxsize = 0\n",
    "    elif callable(maxsize) and isinstance(typed, bool):\n",
    "        # The user_function was passed in directly via the maxsize argument\n",
    "        user_function, maxsize = maxsize, 128\n",
    "        wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)\n",
    "        wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}\n",
    "        return update_wrapper(wrapper, user_function)\n",
    "    elif maxsize is not None:\n",
    "        raise TypeError(\n",
    "            'Expected first argument to be an integer, a callable, or None')\n",
    "\n",
    "    def decorating_function(user_function):\n",
    "        wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo)\n",
    "        wrapper.cache_parameters = lambda : {'maxsize': maxsize, 'typed': typed}\n",
    "        return update_wrapper(wrapper, user_function)\n",
    "\n",
    "    return decorating_function\n",
    "\n",
    "def _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):\n",
    "    # Constants shared by all lru cache instances:\n",
    "    sentinel = object()          # unique object used to signal cache misses\n",
    "    make_key = _make_key         # build a key from the function arguments\n",
    "    PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # names for the link fields\n",
    "\n",
    "    cache = {}\n",
    "    hits = misses = 0\n",
    "    full = False\n",
    "    cache_get = cache.get    # bound method to lookup a key or return None\n",
    "    cache_len = cache.__len__  # get cache size without calling len()\n",
    "    lock = RLock()           # because linkedlist updates aren't threadsafe\n",
    "    root = []                # root of the circular doubly linked list\n",
    "    root[:] = [root, root, None, None]     # initialize by pointing to self\n",
    "\n",
    "    if maxsize == 0:\n",
    "\n",
    "        def wrapper(*args, **kwds):\n",
    "            # No caching -- just a statistics update\n",
    "            nonlocal misses\n",
    "            misses += 1\n",
    "            result = user_function(*args, **kwds)\n",
    "            return result\n",
    "\n",
    "    elif maxsize is None:\n",
    "\n",
    "        def wrapper(*args, **kwds):\n",
    "            # Simple caching without ordering or size limit\n",
    "            nonlocal hits, misses\n",
    "            key = make_key(args, kwds, typed)\n",
    "            result = cache_get(key, sentinel)\n",
    "            if result is not sentinel:\n",
    "                hits += 1\n",
    "                return result\n",
    "            misses += 1\n",
    "            result = user_function(*args, **kwds)\n",
    "            cache[key] = result\n",
    "            return result\n",
    "\n",
    "    else:\n",
    "\n",
    "        def wrapper(*args, **kwds):\n",
    "            # Size limited caching that tracks accesses by recency\n",
    "            nonlocal root, hits, misses, full\n",
    "            key = make_key(args, kwds, typed)\n",
    "            with lock:\n",
    "                link = cache_get(key)\n",
    "                if link is not None:\n",
    "                    # Move the link to the front of the circular queue\n",
    "                    link_prev, link_next, _key, result = link\n",
    "                    link_prev[NEXT] = link_next\n",
    "                    link_next[PREV] = link_prev\n",
    "                    last = root[PREV]\n",
    "                    last[NEXT] = root[PREV] = link\n",
    "                    link[PREV] = last\n",
    "                    link[NEXT] = root\n",
    "                    hits += 1\n",
    "                    return result\n",
    "                misses += 1\n",
    "            result = user_function(*args, **kwds)\n",
    "            with lock:\n",
    "                if key in cache:\n",
    "                    # Getting here means that this same key was added to the\n",
    "                    # cache while the lock was released.  Since the link\n",
    "                    # update is already done, we need only return the\n",
    "                    # computed result and update the count of misses.\n",
    "                    pass\n",
    "                elif full:\n",
    "                    # Use the old root to store the new key and result.\n",
    "                    oldroot = root\n",
    "                    oldroot[KEY] = key\n",
    "                    oldroot[RESULT] = result\n",
    "                    # Empty the oldest link and make it the new root.\n",
    "                    # Keep a reference to the old key and old result to\n",
    "                    # prevent their ref counts from going to zero during the\n",
    "                    # update. That will prevent potentially arbitrary object\n",
    "                    # clean-up code (i.e. __del__) from running while we're\n",
    "                    # still adjusting the links.\n",
    "                    root = oldroot[NEXT]\n",
    "                    oldkey = root[KEY]\n",
    "                    oldresult = root[RESULT]\n",
    "                    root[KEY] = root[RESULT] = None\n",
    "                    # Now update the cache dictionary.\n",
    "                    del cache[oldkey]\n",
    "                    # Save the potentially reentrant cache[key] assignment\n",
    "                    # for last, after the root and links have been put in\n",
    "                    # a consistent state.\n",
    "                    cache[key] = oldroot\n",
    "                else:\n",
    "                    # Put result in a new link at the front of the queue.\n",
    "                    last = root[PREV]\n",
    "                    link = [last, root, key, result]\n",
    "                    last[NEXT] = root[PREV] = cache[key] = link\n",
    "                    # Use the cache_len bound method instead of the len() function\n",
    "                    # which could potentially be wrapped in an lru_cache itself.\n",
    "                    full = (cache_len() >= maxsize)\n",
    "            return result\n",
    "\n",
    "    def cache_info():\n",
    "        \"\"\"Report cache statistics\"\"\"\n",
    "        with lock:\n",
    "            return _CacheInfo(hits, misses, maxsize, cache_len())\n",
    "\n",
    "    def cache_clear():\n",
    "        \"\"\"Clear the cache and cache statistics\"\"\"\n",
    "        nonlocal hits, misses, full\n",
    "        with lock:\n",
    "            cache.clear()\n",
    "            root[:] = [root, root, None, None]\n",
    "            hits = misses = 0\n",
    "            full = False\n",
    "\n",
    "    wrapper.cache_info = cache_info\n",
    "    wrapper.cache_clear = cache_clear\n",
    "    return wrapper\n",
    "\n",
    "try:\n",
    "    from _functools import _lru_cache_wrapper\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### cache -- simplified access to the infinity cache\n",
    "################################################################################\n",
    "\n",
    "def cache(user_function, /):\n",
    "    'Simple lightweight unbounded cache.  Sometimes called \"memoize\".'\n",
    "    return lru_cache(maxsize=None)(user_function)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### singledispatch() - single-dispatch generic function decorator\n",
    "################################################################################\n",
    "\n",
    "def _c3_merge(sequences):\n",
    "    \"\"\"Merges MROs in *sequences* to a single MRO using the C3 algorithm.\n",
    "    Adapted from https://www.python.org/download/releases/2.3/mro/.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    while True:\n",
    "        sequences = [s for s in sequences if s]   # purge empty sequences\n",
    "        if not sequences:\n",
    "            return result\n",
    "        for s1 in sequences:   # find merge candidates among seq heads\n",
    "            candidate = s1[0]\n",
    "            for s2 in sequences:\n",
    "                if candidate in s2[1:]:\n",
    "                    candidate = None\n",
    "                    break      # reject the current head, it appears later\n",
    "            else:\n",
    "                break\n",
    "        if candidate is None:\n",
    "            raise RuntimeError(\"Inconsistent hierarchy\")\n",
    "        result.append(candidate)\n",
    "        # remove the chosen candidate\n",
    "        for seq in sequences:\n",
    "            if seq[0] == candidate:\n",
    "                del seq[0]\n",
    "\n",
    "def _c3_mro(cls, abcs=None):\n",
    "    \"\"\"Computes the method resolution order using extended C3 linearization.\n",
    "    If no *abcs* are given, the algorithm works exactly like the built-in C3\n",
    "    linearization used for method resolution.\n",
    "    If given, *abcs* is a list of abstract base classes that should be inserted\n",
    "    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the\n",
    "    result. The algorithm inserts ABCs where their functionality is introduced,\n",
    "    i.e. issubclass(cls, abc) returns True for the class itself but returns\n",
    "    False for all its direct base classes. Implicit ABCs for a given class\n",
    "    (either registered or inferred from the presence of a special method like\n",
    "    __len__) are inserted directly after the last ABC explicitly listed in the\n",
    "    MRO of said class. If two implicit ABCs end up next to each other in the\n",
    "    resulting MRO, their ordering depends on the order of types in *abcs*.\n",
    "    \"\"\"\n",
    "    for i, base in enumerate(reversed(cls.__bases__)):\n",
    "        if hasattr(base, '__abstractmethods__'):\n",
    "            boundary = len(cls.__bases__) - i\n",
    "            break   # Bases up to the last explicit ABC are considered first.\n",
    "    else:\n",
    "        boundary = 0\n",
    "    abcs = list(abcs) if abcs else []\n",
    "    explicit_bases = list(cls.__bases__[:boundary])\n",
    "    abstract_bases = []\n",
    "    other_bases = list(cls.__bases__[boundary:])\n",
    "    for base in abcs:\n",
    "        if issubclass(cls, base) and not any(\n",
    "                issubclass(b, base) for b in cls.__bases__\n",
    "            ):\n",
    "            # If *cls* is the class that introduces behaviour described by\n",
    "            # an ABC *base*, insert said ABC to its MRO.\n",
    "            abstract_bases.append(base)\n",
    "    for base in abstract_bases:\n",
    "        abcs.remove(base)\n",
    "    explicit_c3_mros = [_c3_mro(base, abcs=abcs) for base in explicit_bases]\n",
    "    abstract_c3_mros = [_c3_mro(base, abcs=abcs) for base in abstract_bases]\n",
    "    other_c3_mros = [_c3_mro(base, abcs=abcs) for base in other_bases]\n",
    "    return _c3_merge(\n",
    "        [[cls]] +\n",
    "        explicit_c3_mros + abstract_c3_mros + other_c3_mros +\n",
    "        [explicit_bases] + [abstract_bases] + [other_bases]\n",
    "    )\n",
    "\n",
    "def _compose_mro(cls, types):\n",
    "    \"\"\"Calculates the method resolution order for a given class *cls*.\n",
    "    Includes relevant abstract base classes (with their respective bases) from\n",
    "    the *types* iterable. Uses a modified C3 linearization algorithm.\n",
    "    \"\"\"\n",
    "    bases = set(cls.__mro__)\n",
    "    # Remove entries which are already present in the __mro__ or unrelated.\n",
    "    def is_related(typ):\n",
    "        return (typ not in bases and hasattr(typ, '__mro__')\n",
    "                                 and not isinstance(typ, GenericAlias)\n",
    "                                 and issubclass(cls, typ))\n",
    "    types = [n for n in types if is_related(n)]\n",
    "    # Remove entries which are strict bases of other entries (they will end up\n",
    "    # in the MRO anyway.\n",
    "    def is_strict_base(typ):\n",
    "        for other in types:\n",
    "            if typ != other and typ in other.__mro__:\n",
    "                return True\n",
    "        return False\n",
    "    types = [n for n in types if not is_strict_base(n)]\n",
    "    # Subclasses of the ABCs in *types* which are also implemented by\n",
    "    # *cls* can be used to stabilize ABC ordering.\n",
    "    type_set = set(types)\n",
    "    mro = []\n",
    "    for typ in types:\n",
    "        found = []\n",
    "        for sub in typ.__subclasses__():\n",
    "            if sub not in bases and issubclass(cls, sub):\n",
    "                found.append([s for s in sub.__mro__ if s in type_set])\n",
    "        if not found:\n",
    "            mro.append(typ)\n",
    "            continue\n",
    "        # Favor subclasses with the biggest number of useful bases\n",
    "        found.sort(key=len, reverse=True)\n",
    "        for sub in found:\n",
    "            for subcls in sub:\n",
    "                if subcls not in mro:\n",
    "                    mro.append(subcls)\n",
    "    return _c3_mro(cls, abcs=mro)\n",
    "\n",
    "def _find_impl(cls, registry):\n",
    "    \"\"\"Returns the best matching implementation from *registry* for type *cls*.\n",
    "    Where there is no registered implementation for a specific type, its method\n",
    "    resolution order is used to find a more generic implementation.\n",
    "    Note: if *registry* does not contain an implementation for the base\n",
    "    *object* type, this function may return None.\n",
    "    \"\"\"\n",
    "    mro = _compose_mro(cls, registry.keys())\n",
    "    match = None\n",
    "    for t in mro:\n",
    "        if match is not None:\n",
    "            # If *match* is an implicit ABC but there is another unrelated,\n",
    "            # equally matching implicit ABC, refuse the temptation to guess.\n",
    "            if (t in registry and t not in cls.__mro__\n",
    "                              and match not in cls.__mro__\n",
    "                              and not issubclass(match, t)):\n",
    "                raise RuntimeError(\"Ambiguous dispatch: {} or {}\".format(\n",
    "                    match, t))\n",
    "            break\n",
    "        if t in registry:\n",
    "            match = t\n",
    "    return registry.get(match)\n",
    "\n",
    "def singledispatch(func):\n",
    "    \"\"\"Single-dispatch generic function decorator.\n",
    "    Transforms a function into a generic function, which can have different\n",
    "    behaviours depending upon the type of its first argument. The decorated\n",
    "    function acts as the default implementation, and additional\n",
    "    implementations can be registered using the register() attribute of the\n",
    "    generic function.\n",
    "    \"\"\"\n",
    "    # There are many programs that use functools without singledispatch, so we\n",
    "    # trade-off making singledispatch marginally slower for the benefit of\n",
    "    # making start-up of such applications slightly faster.\n",
    "    import types, weakref\n",
    "\n",
    "    registry = {}\n",
    "    dispatch_cache = weakref.WeakKeyDictionary()\n",
    "    cache_token = None\n",
    "\n",
    "    def dispatch(cls):\n",
    "        \"\"\"generic_func.dispatch(cls) -> <function implementation>\n",
    "        Runs the dispatch algorithm to return the best available implementation\n",
    "        for the given *cls* registered on *generic_func*.\n",
    "        \"\"\"\n",
    "        nonlocal cache_token\n",
    "        if cache_token is not None:\n",
    "            current_token = get_cache_token()\n",
    "            if cache_token != current_token:\n",
    "                dispatch_cache.clear()\n",
    "                cache_token = current_token\n",
    "        try:\n",
    "            impl = dispatch_cache[cls]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                impl = registry[cls]\n",
    "            except KeyError:\n",
    "                impl = _find_impl(cls, registry)\n",
    "            dispatch_cache[cls] = impl\n",
    "        return impl\n",
    "\n",
    "    def _is_union_type(cls):\n",
    "        from typing import get_origin, Union\n",
    "        return get_origin(cls) in {Union, types.UnionType}\n",
    "\n",
    "    def _is_valid_dispatch_type(cls):\n",
    "        if isinstance(cls, type):\n",
    "            return True\n",
    "        from typing import get_args\n",
    "        return (_is_union_type(cls) and\n",
    "                all(isinstance(arg, type) for arg in get_args(cls)))\n",
    "\n",
    "    def register(cls, func=None):\n",
    "        \"\"\"generic_func.register(cls, func) -> func\n",
    "        Registers a new implementation for the given *cls* on a *generic_func*.\n",
    "        \"\"\"\n",
    "        nonlocal cache_token\n",
    "        if _is_valid_dispatch_type(cls):\n",
    "            if func is None:\n",
    "                return lambda f: register(cls, f)\n",
    "        else:\n",
    "            if func is not None:\n",
    "                raise TypeError(\n",
    "                    f\"Invalid first argument to `register()`. \"\n",
    "                    f\"{cls!r} is not a class or union type.\"\n",
    "                )\n",
    "            ann = getattr(cls, '__annotations__', {})\n",
    "            if not ann:\n",
    "                raise TypeError(\n",
    "                    f\"Invalid first argument to `register()`: {cls!r}. \"\n",
    "                    f\"Use either `@register(some_class)` or plain `@register` \"\n",
    "                    f\"on an annotated function.\"\n",
    "                )\n",
    "            func = cls\n",
    "\n",
    "            # only import typing if annotation parsing is necessary\n",
    "            from typing import get_type_hints\n",
    "            argname, cls = next(iter(get_type_hints(func).items()))\n",
    "            if not _is_valid_dispatch_type(cls):\n",
    "                if _is_union_type(cls):\n",
    "                    raise TypeError(\n",
    "                        f\"Invalid annotation for {argname!r}. \"\n",
    "                        f\"{cls!r} not all arguments are classes.\"\n",
    "                    )\n",
    "                else:\n",
    "                    raise TypeError(\n",
    "                        f\"Invalid annotation for {argname!r}. \"\n",
    "                        f\"{cls!r} is not a class.\"\n",
    "                    )\n",
    "\n",
    "        if _is_union_type(cls):\n",
    "            from typing import get_args\n",
    "\n",
    "            for arg in get_args(cls):\n",
    "                registry[arg] = func\n",
    "        else:\n",
    "            registry[cls] = func\n",
    "        if cache_token is None and hasattr(cls, '__abstractmethods__'):\n",
    "            cache_token = get_cache_token()\n",
    "        dispatch_cache.clear()\n",
    "        return func\n",
    "\n",
    "    def wrapper(*args, **kw):\n",
    "        if not args:\n",
    "            raise TypeError(f'{funcname} requires at least '\n",
    "                            '1 positional argument')\n",
    "\n",
    "        return dispatch(args[0].__class__)(*args, **kw)\n",
    "\n",
    "    funcname = getattr(func, '__name__', 'singledispatch function')\n",
    "    registry[object] = func\n",
    "    wrapper.register = register\n",
    "    wrapper.dispatch = dispatch\n",
    "    wrapper.registry = types.MappingProxyType(registry)\n",
    "    wrapper._clear_cache = dispatch_cache.clear\n",
    "    update_wrapper(wrapper, func)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# Descriptor version\n",
    "class singledispatchmethod:\n",
    "    \"\"\"Single-dispatch generic method descriptor.\n",
    "    Supports wrapping existing descriptors and handles non-descriptor\n",
    "    callables as instance methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, func):\n",
    "        if not callable(func) and not hasattr(func, \"__get__\"):\n",
    "            raise TypeError(f\"{func!r} is not callable or a descriptor\")\n",
    "\n",
    "        self.dispatcher = singledispatch(func)\n",
    "        self.func = func\n",
    "\n",
    "    def register(self, cls, method=None):\n",
    "        \"\"\"generic_method.register(cls, func) -> func\n",
    "        Registers a new implementation for the given *cls* on a *generic_method*.\n",
    "        \"\"\"\n",
    "        return self.dispatcher.register(cls, func=method)\n",
    "\n",
    "    def __get__(self, obj, cls=None):\n",
    "        def _method(*args, **kwargs):\n",
    "            method = self.dispatcher.dispatch(args[0].__class__)\n",
    "            return method.__get__(obj, cls)(*args, **kwargs)\n",
    "\n",
    "        _method.__isabstractmethod__ = self.__isabstractmethod__\n",
    "        _method.register = self.register\n",
    "        update_wrapper(_method, self.func)\n",
    "        return _method\n",
    "\n",
    "    @property\n",
    "    def __isabstractmethod__(self):\n",
    "        return getattr(self.func, '__isabstractmethod__', False)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### cached_property() - computed once per instance, cached as attribute\n",
    "################################################################################\n",
    "\n",
    "_NOT_FOUND = object()\n",
    "\n",
    "\n",
    "class cached_property:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.attrname = None\n",
    "        self.__doc__ = func.__doc__\n",
    "        self.lock = RLock()\n",
    "\n",
    "    def __set_name__(self, owner, name):\n",
    "        if self.attrname is None:\n",
    "            self.attrname = name\n",
    "        elif name != self.attrname:\n",
    "            raise TypeError(\n",
    "                \"Cannot assign the same cached_property to two different names \"\n",
    "                f\"({self.attrname!r} and {name!r}).\"\n",
    "            )\n",
    "\n",
    "    def __get__(self, instance, owner=None):\n",
    "        if instance is None:\n",
    "            return self\n",
    "        if self.attrname is None:\n",
    "            raise TypeError(\n",
    "                \"Cannot use cached_property instance without calling __set_name__ on it.\")\n",
    "        try:\n",
    "            cache = instance.__dict__\n",
    "        except AttributeError:  # not all objects have __dict__ (e.g. class defines slots)\n",
    "            msg = (\n",
    "                f\"No '__dict__' attribute on {type(instance).__name__!r} \"\n",
    "                f\"instance to cache {self.attrname!r} property.\"\n",
    "            )\n",
    "            raise TypeError(msg) from None\n",
    "        val = cache.get(self.attrname, _NOT_FOUND)\n",
    "        if val is _NOT_FOUND:\n",
    "            with self.lock:\n",
    "                # check if another thread filled cache while we awaited lock\n",
    "                val = cache.get(self.attrname, _NOT_FOUND)\n",
    "                if val is _NOT_FOUND:\n",
    "                    val = self.func(instance)\n",
    "                    try:\n",
    "                        cache[self.attrname] = val\n",
    "                    except TypeError:\n",
    "                        msg = (\n",
    "                            f\"The '__dict__' attribute on {type(instance).__name__!r} instance \"\n",
    "                            f\"does not support item assignment for caching {self.attrname!r} property.\"\n",
    "                        )\n",
    "                        raise TypeError(msg) from None\n",
    "        return val\n",
    "\n",
    "    __class_getitem__ = classmethod(GenericAlias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61cb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
